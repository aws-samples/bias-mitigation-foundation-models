{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18febc2a-572f-4bd1-aa4b-2b1669612bdb",
   "metadata": {},
   "source": [
    "# Part 2 - Mitigating bias in text-image models.\n",
    "\n",
    "> *This notebook should work well in the `Data Science 3.0` kernel on Amazon SageMaker Studio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d37adc-0994-4304-a82f-0edb063ff1cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --quiet \"boto3>=1.28.63,<2\" \"botocore>=1.31.63,<2\" langchain==0.0.336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441a4c3b-168e-4643-91da-3ab89de3ea0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Python Built-Ins:\n",
    "import base64\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3  # AWS SDK for Python\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from PIL import Image  # For processing and displaying images\n",
    "\n",
    "boto3_bedrock = boto3.client(\"bedrock-runtime\")\n",
    "os.makedirs(\"data\", exist_ok=True)  # We'll save our generated pictures here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708bef56-396b-4fe1-b9c4-410946edde75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_model_id = \"stability.stable-diffusion-xl\"\n",
    "image_model_config = {\n",
    "    \"cfg_scale\": 5,\n",
    "    \"seed\": 42,\n",
    "    \"steps\": 70,\n",
    "    \"style_preset\": \"photographic\",\n",
    "}\n",
    "\n",
    "\n",
    "def invoke_image_gen(prompts: List[str], negative_prompts: List[str], **kwargs,) -> Image.Image:\n",
    "    request = json.dumps({\n",
    "        **image_model_config,\n",
    "        \"text_prompts\": (\n",
    "            [{\"text\": prompt, \"weight\": 1.0} for prompt in prompts]\n",
    "            + [{\"text\": negprompt, \"weight\": -1.0} for negprompt in negative_prompts]\n",
    "        ),\n",
    "        **kwargs,\n",
    "    })\n",
    "\n",
    "    response = boto3_bedrock.invoke_model(body=request, modelId=image_model_id)\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "    print(response_body[\"result\"])\n",
    "    base_64_img_str = response_body[\"artifacts\"][0].get(\"base64\")\n",
    "    print(f\"{base_64_img_str[0:80]}...\")\n",
    "    return Image.open(io.BytesIO(base64.decodebytes(bytes(base_64_img_str, \"utf-8\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0e4285-6665-48a3-bb4c-aa0681e93928",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "negative_prompts = [\n",
    "    \"bias\",\n",
    "    \"discriminatory\",\n",
    "    \"poorly rendered\",\n",
    "    \"poor background details\",\n",
    "    \"poorly drawn features\",\n",
    "    \"disfigured features\",\n",
    "]\n",
    "\n",
    "image_1 = invoke_image_gen([\"a doctor in a hospital\"], negative_prompts)\n",
    "image_1.save(\"data/image_1.png\")\n",
    "image_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7581f9d5-79c2-4c88-bb5a-446b2bb9700f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_2 = invoke_image_gen(\n",
    "    [\n",
    "        \"a doctor in a hospital\",\n",
    "        \"inclusive of male and female\",\n",
    "    ],\n",
    "    negative_prompts,\n",
    ")\n",
    "image_2.save(\"data/image_2.png\")\n",
    "image_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb8e3ba-a826-41c6-acc0-4556c0b78b09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_3 = invoke_image_gen(\n",
    "    [\n",
    "        \"a doctor in a hospital\",\n",
    "        \"inclusive of male, female, and color\",\n",
    "    ],\n",
    "    negative_prompts,\n",
    ")\n",
    "image_3.save(\"data/image_3.png\")\n",
    "image_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d26179-5c79-4383-8bf0-09bdb5314822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_4 = invoke_image_gen(\n",
    "    [\"a nurse in a hospital\"],\n",
    "    [\"bias and discrimination against certain group of people\"],\n",
    ")\n",
    "image_4.save(\"data/image_4.png\")\n",
    "image_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90bcd9a-b2de-4a50-84e9-e20772aeb9de",
   "metadata": {},
   "source": [
    "### Bias mitigation\n",
    "Steps:\n",
    "- Use a LLM to generate prompts which are non-discriminatory and try to remove bias from the prompt. \n",
    "- Use the generated prompt to create an image. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f13c2ee-1ac7-4dcc-86c9-973d2e599a70",
   "metadata": {},
   "source": [
    "#### Step 1: Create a chatbot application to generate inclusive prompts. \n",
    "The chatbot will make sure to ask relevant questions to the user before generating the prompt for `text-image` model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ea5877-d969-4d38-9412-3b69bc159da8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "cl_llm = Bedrock(\n",
    "    model_id=\"anthropic.claude-instant-v1\",\n",
    "    client=boto3_bedrock,\n",
    "    model_kwargs={\"max_tokens_to_sample\": 1000, \"temperature\": 0.0},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b990dc3-771d-433e-9071-860c853ef05c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "\n",
    "memory = ConversationBufferMemory(ai_prefix=\"Assistant\")\n",
    "# turn verbose to true to see the full logs and documents\n",
    "conversation = ConversationChain(llm=cl_llm, verbose=False, memory=memory)\n",
    "\n",
    "# langchain prompts do not always work with all the models. This prompt is tuned for Claude\n",
    "chat_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Human:\n",
    "You are a prompt generator, who generates prompts for text to image models based on a user question.\n",
    "You and the image AI are not biased and do not discriminate against certain groups of people.\n",
    "If you detect bias in the question, ask relevant questions based on gender, race and color before\n",
    "generating the prompt. If you don't know the answer to a question, truthfully say you don't know.\n",
    "If the image generation question includes human beings, ask all of the following questions with\n",
    "examples before generating the image prompt:\n",
    "\n",
    "<questions>\n",
    "- What is the gender of the subject in the picture? (e.g. male, female, transgender etc.)\n",
    "- What is the color of the subject in the image? (e.g. white, black, or brown etc.)\n",
    "- What is the race of the subject in the image? (e.g. African-american, latino, indian, korean,\n",
    "  chineese, asian, etc.)\n",
    "</questions>\n",
    "\n",
    "When you are ready to generate the image prompt, return it in <imageprompt></imageprompt> XML tags.\n",
    "\n",
    "Assistant:\n",
    "OK, I understand\n",
    "\n",
    "{history}\n",
    "\n",
    "Human:\n",
    "{input}\n",
    "\n",
    "Assistant:\n",
    "\"\"\")\n",
    "\n",
    "conversation.prompt = chat_prompt\n",
    "\n",
    "print(conversation.predict(input=\"Hi there!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94850251-d4ba-43d8-be97-e16f2c292105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(conversation.predict(input=\"photo of a doctor.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec4907a-3811-4c25-9ea1-c645d6166449",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = conversation.predict(input=\"Hispanic brown female\")\n",
    "print(response)\n",
    "\n",
    "# Try to extract just the image prompt component of the response:\n",
    "ix_prompt_start = response.find(\"<imageprompt>\") + len(\"<imageprompt>\")\n",
    "ix_prompt_end = response.find(\"</imageprompt>\", ix_prompt_start)\n",
    "img_prompt = response[ix_prompt_start:ix_prompt_end].strip()\n",
    "print(\"\\n\\n------------------------\\n\" + img_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04561dda-2935-490a-bf3e-5b7f10f928f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_disambiguated = invoke_image_gen([img_prompt], negative_prompts)\n",
    "image_disambiguated.save(\"data/image_disambiguated.png\")\n",
    "image_disambiguated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4844d257-0376-47e5-a5e4-07c4d26ccc68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
